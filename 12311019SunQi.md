## Q1

### Pt1.

#### Pretraining

- **目标**：
   在超大规模非标注语料上做语言建模（如Next Token Prediction），让模型学会通用的语言分布和世界知识。
- **获得的能力**：
  - 语法、语义理解与生成
  - 基本常识与世界知识
  - 一定程度的推理、翻译、摘要等“涌现”能力
- **主要挑战**：
  - 需要极大的数据和算力，训练成本高
  - 训练目标只管“像人类文本”，不保证真实、无害或有用，会产生幻觉、偏见、有害内容
  - 数据噪声大、分布多样，优化和稳定性有难度
- **代表模型**：GPT-3、PaLM、LLaMA 等基础大模型

#### Instruction Tuning

- **目标**：
   用人工整理的  数据对预训练模型做监督微调（SFT），使其更好地理解并遵循自然语言指令\。
- **获得的能力**：
  - 更好地“听人话”
  - 能在同一模型内泛化到多任务（问答、翻译、写代码等）
  - 格式更规范、回答更聚焦任务本身
- **主要挑战**：
  - 构造高质量、覆盖广、少模板化的指令数据集比较昂贵
  - 容易过拟合少量指令风格，导致回复刻板
  - 不同指令之间可能互相冲突，统一行为较难
- **代表模型**：InstructGPT、FLAN-T5、LLaMA-2-Chat（SFT 阶段）等

#### Alignment Tuning

- **目标**：
   通过人类偏好反馈（如 RLHF、规则驱动的宪法式 AI 等），让模型符合人类价值观和安全要求，兼顾有用（helpful），无害（harmless），诚实（honest）。
- **获得的能力**：
  - 主动拒绝违法、危险或明显有害的请求
  - 说话更礼貌、有边界，减少攻击性与偏见
  - 回答更贴近人类偏好：更清晰、结构化
- **主要挑战**：
  - 高质量偏好标注昂贵且带有主观性，不同群体价值观不一致
  - RLHF 中存在“奖励黑客”、训练不稳定等问题
  - 只能在有限标注数据上近似人类价值，仍可能出现对齐失效
- **代表模型**：ChatGPT（例如 GPT-3.5/4 经 RLHF）、Claude、Gemini 等对话安全模型

### Pt2.

#### Emergent Abilities

一些能力很可能只存在于大型模型中，而不存在于小型模型中。

#### Examples

博客提到了以下几种例子

+ **复杂推理**：如 GSM8K 数学题上，百亿参数以上模型配合链式思维提示，性能突然大幅超越传统微调模型，而且只需要少量带思维过程的示例。

+ **带知识的推理**：在问答和常识任务上，大模型可以不用外部检索，只依靠预训练内化的知识，通过 prompt 就达到接近或超过以往“检索 + 小模型”的系统。

+ **分布外鲁棒性**：在领域转移、加噪声、对抗扰动等分布外设置中，大模型的性能下降更小，某些情况下甚至超过原本在同分布上更强的小模型。

### Pt3.

#### Results and Analysis

GSM8K + zero shot

```
gsm8k length==== 1319 , gsm8k acc==== 0.40365296803652967
```

5 shot

```
gsm8k length==== 1319 , gsm8k acc==== 0.1417740712661107
```

## Q2

### Pt1.

#### Diversity filtering

在大模型生成了很多候选数据之后，去掉那些“太像彼此”的样本，只保留内容多样、覆盖面广的一部分，避免数据高度重复、模式单一。

代表性方法：ROUGE-L 去重

- 做法：计算新生成样本与已有样本之间的 ROUGE-L 分数（衡量两个序列的最长公共子序列比例）。
- 如果 ROUGE-L 很高，说明这条样本和已有的某条样本内容非常相似，就把它丢弃或降权。

#### Quality filtering

从已经生成的数据里，筛掉那些写得差、逻辑乱、风格不符合要求的样本，只留下整体质量较高的。

代表性方法：Reward Model打分

- 先训练一个 reward model，输入是（prompt, 输出），输出一个质量评分（越高代表越好）。
- 生成完候选样本后，让 reward model 给每条样本打分，只保留分数最高的 top-k，或者给分数低于某个阈值的样本全部扔掉。
- 这个 reward model 可以综合考虑：流畅度、礼貌性、任务完成度、是否遵守指令等。

#### Correctness filtering

 专门从“是否正确、是否与事实或标准答案一致”这个角度来过滤数据，尤其常见于有标准答案或可验证结果的任务。

为什么要做：

- 高质量但错的回答，比低质量还危险：模型会学到“很自信但错误”的模式。
- 对于可验证任务，完全可以用自动方式检查正确与否，那就没必要保留错例。

一个代表性方法：Final Answer Verification

- 对于有标准答案的问题（如：数学题、编程题）：
  1. 让模型生成一步步推理 + 最终答案。
  2. 用一个验证器检查最终答案是否等于标准答案，或者代码是否能通过测试用例。
  3. 只有“验证通过”的样本才被保留进训练数据。
- 对于没有显式标准答案的任务，也可以用另一个模型/多个模型来交叉检查，做类似的“自校验”或“多样本一致性验证”。

### Pt2.

调用了千问百炼平台的API，model选择Qwen-plus进行回答，评分规则如下。
$$
Reward_{\text{total}} = S_{len} * w_{len} + S_{keyword} * w_{keyword} + S_{Jaccard} * w_{sim}
$$
可通过调整权重满足不同需求。

结果如下

```
================================================================================
Prompt 1: Explain the difference between supervised and unsupervised learning.
参考答案: Supervised learning trains models on labeled data, while unsupervised learning uses unlabeled data to discover hidden structure or patterns.
--------------------------------------------------------------------------------
Candidate 1: 监督学习和无监督学习的主要区别在于数据是否带有标签：

- **监督学习**：训练数据包含输入特征和对应的标签（正确答案）。模型通过学习输入与标签之间的关系，进行预测。例如分类（识别图片是猫还是狗）和回归（预测房价）。

- **无监督学习**：训练数据没有标签，模型需要自行发现数据中的结构或模式。常见任务包括聚类（将相似数据分组）和降维（减少数据维度）。

简言之：  
监督学习“有答案”可学，目标是预测；  
无监督学习“无答案”，目标是探索数据内在规律。
  -> Score = 0.2061 (len=0.687, kw=0.000, sim=0.000)

Candidate 2: 监督学习和无监督学习的主要区别在于数据是否带有标签：

- **监督学习**：训练数据包含输入特征和对应的标签（正确答案）。模型通过学习输入与标签之间的关系，进行预测。例如：分类（判断邮件是否为垃圾邮件）和回归（预测房价）。

- **无监督学习**：训练数据没有标签，模型需要自行发现数据中的结构或模式。例如：聚类（将客户分成不同群体）和降维（压缩数据维度）。

简言之：  
监督学习“知道答案”，目标是预测；  
无监督学习“不知道答案”，目标是探索数据。
  -> Score = 0.2293 (len=0.764, kw=0.000, sim=0.000)

Candidate 3: 监督学习和无监督学习的主要区别在于数据是否带有标签：

- **监督学习**：训练数据包含输入特征和对应的标签（正确答案）。模型通过学习输入与标签之间的关系，进行预测。例如分类（判断邮件是否为垃圾邮件）和回归（预测房价）。

- **无监督学习**：训练数据没有标签，模型自行发现数据中的结构或模式。常见任务包括聚类（如客户分群）和降维（如数据可视化）。

简言之：监督学习“有答案”，无监督学习“找规律”。
  -> Score = 0.1820 (len=0.607, kw=0.000, sim=0.000)

Selected: Candidate 2

================================================================================
Prompt 2: Describe overfitting in one sentence.
参考答案: Overfitting happens when a model performs very well on the training set but generalizes poorly to new, unseen data.
--------------------------------------------------------------------------------
Candidate 1: 过拟合是指模型在训练数据上表现很好，但在新数据上表现差，因为它过度学习了训练数据的噪声和细节。
  -> Score = 0.0594 (len=0.198, kw=0.000, sim=0.000)

Candidate 2: 过拟合是指模型在训练数据上表现很好，但在新数据上表现差，因为它过度学习了训练数据的噪声和细节。
  -> Score = 0.0594 (len=0.198, kw=0.000, sim=0.000)

Candidate 3: 过拟合是指模型在训练数据上表现很好，但在新数据上表现差，因为它过度学习了训练数据的噪声和细节。
  -> Score = 0.0594 (len=0.198, kw=0.000, sim=0.000)

Selected: Candidate 1

================================================================================
Prompt 3: Briefly explain the main idea of gradient descent.
参考答案: Gradient descent iteratively updates model parameters in the opposite direction of the loss function's gradient to gradually reduce the loss.
--------------------------------------------------------------------------------
Candidate 1: 梯度下降是一种优化算法，用于最小化目标函数。其核心思想是：从初始点出发，沿着目标函数在该点的负梯度方向逐步迭代更新参数，因为负梯度方向是函数下降最快的方向，最终逼近函数的最小值点。
  -> Score = 0.0926 (len=0.309, kw=0.000, sim=0.000)

Candidate 2: 梯度下降是一种优化算法，用于最小化目标函数。其核心思想是：从初始点出发，沿着目标函数梯度的反方向逐步迭代更新参数，因为梯度方向是函数上升最快的方向，所以负梯度方向是下降最快的方向。通过不断迭代，逐渐逼近函数的最小值点。学习率控制每一步的更新步长。
  -> Score = 0.1233 (len=0.411, kw=0.000, sim=0.000)

Candidate 3: 梯度下降是一种优化算法，用于最小化损失函数。其核心思想是：从初始点出发，沿着损失函数梯度的反方向逐步调整参数，因为梯度方向是函数上升最快的方向，反方向就是下降最快的方向。通过不断迭代更新参数，最终逼近函数的最小值点。
  -> Score = 0.1126 (len=0.375, kw=0.000, sim=0.000)

Selected: Candidate 2

================================================================================
Prompt 4: What is an activation function in a neural network? Give one example.
参考答案: An activation function introduces non-linearity into a neuron’s output, such as ReLU or Sigmoid.
--------------------------------------------------------------------------------
Candidate 1: 激活函数是神经网络中用于决定神经元是否被激活的函数，它引入非线性，使网络能够学习复杂模式。  
例如：ReLU（修正线性单元）函数，定义为 f(x) = max(0, x)。
  -> Score = 0.1983 (len=0.411, kw=0.250, sim=0.000)

Candidate 2: 激活函数是神经网络中用于决定神经元是否被激活的函数，它引入非线性，使网络能够学习复杂模式。  
例如：ReLU函数，定义为 f(x) = max(0, x)。
  -> Score = 0.1983 (len=0.411, kw=0.250, sim=0.000)

Candidate 3: 激活函数是神经网络中用于决定神经元是否应该被激活的函数，它引入非线性，使网络能够学习复杂模式。  
例子：ReLU（修正线性单元）函数，定义为 f(x) = max(0, x)。
  -> Score = 0.1983 (len=0.411, kw=0.250, sim=0.000)

Selected: Candidate 1

================================================================================
Prompt 5: Why do we split a dataset into training and test sets?
参考答案: We split data into training and test sets to evaluate how well the model generalizes to unseen data instead of just memorizing the training data.
--------------------------------------------------------------------------------
Candidate 1: 为了评估模型的泛化能力。用训练集训练模型，用独立的测试集检验模型在未见过的数据上的表现，避免过拟合，确保模型具有实际应用价值。
  -> Score = 0.0748 (len=0.249, kw=0.000, sim=0.000)

Candidate 2: 为了评估模型的泛化能力，我们把数据集分为训练集和测试集。用训练集训练模型，用测试集模拟未知数据来检验模型效果，避免过拟合，确保模型在新数据上也能表现良好。
  -> Score = 0.0834 (len=0.278, kw=0.000, sim=0.000)

Candidate 3: 为了评估模型的泛化能力。训练集用于训练模型，测试集用于模拟未知数据，检验模型在未见过的数据上的表现，避免过拟合。
  -> Score = 0.0748 (len=0.249, kw=0.000, sim=0.000)

Selected: Candidate 2

================================================================================
Prompt 6: What is the learning rate and how does it affect training?
参考答案: The learning rate controls the step size of each parameter update; if it is too large training may diverge, and if it is too small convergence will be very slow.
--------------------------------------------------------------------------------
Candidate 1: 学习率（Learning Rate）是训练神经网络时的一个超参数，控制每次更新模型权重的步长大小。

影响：
- **学习率过大**：权重更新步子太大，可能导致损失震荡，无法收敛，甚至发散。
- **学习率过小**：收敛速度慢，训练时间长，可能陷入局部最小值或鞍点。

合适的学习率能加快收敛并提升模型性能。常用策略包括学习率衰减、预热和使用自适应优化器（如Adam）。
  -> Score = 0.2061 (len=0.687, kw=0.000, sim=0.000)

Candidate 2: 学习率（learning rate）是训练神经网络时的一个超参数，控制每次更新模型权重的步长大小。

影响：
- **学习率太大**：权重更新步子太大，可能跳过最优解，导致训练不稳定或发散。
- **学习率太小**：收敛非常慢，训练时间长，可能陷入局部最小值。

合适的学习率能加快收敛并找到更好的解。通常通过实验或使用学习率调度策略来调整。
  -> Score = 0.2691 (len=0.647, kw=0.250, sim=0.000)

Candidate 3: 学习率（Learning Rate）是训练神经网络时的一个超参数，控制每次更新模型权重的步长大小。

影响：
- **学习率过大**：权重更新步子太大，可能导致损失震荡，无法收敛，甚至发散。
- **学习率过小**：收敛速度慢，训练时间长，可能陷入局部最小值或鞍点。

合适的学习率能加快收敛、提高模型性能。通常通过实验或使用学习率调度策略（如衰减）来调整。
  -> Score = 0.2061 (len=0.687, kw=0.000, sim=0.000)

Selected: Candidate 2

================================================================================
Prompt 7: Explain TP, FP, TN, and FN in a confusion matrix.
参考答案: TP is true positive, FP is false positive, TN is true negative, and FN is false negative, representing the four combinations of predicted and actual labels.
--------------------------------------------------------------------------------
Candidate 1: 在混淆矩阵中，TP、FP、TN、FN 用于评估分类模型的性能，具体如下：

- **TP（True Positive，真正例）**：实际为正类，预测也为正类。  
- **FP（False Positive，假正例）**：实际为负类，但预测为正类（误报）。  
- **TN（True Negative，真负例）**：实际为负类，预测也为负类。  
- **FN（False Negative，假负例）**：实际为正类，但预测为负类（漏报）。

举个例子（疾病检测）：
- 患病者被正确诊断为患病 → TP  
- 健康人被误诊为患病 → FP  
- 健康人被正确诊断为健康 → TN  
- 患病者被漏诊为健康 → FN

这些值用于计算准确率、精确率、召回率等指标。
  -> Score = 0.5046 (len=0.566, kw=1.000, sim=0.087)

Candidate 2: 在混淆矩阵中：

- **TP（True Positive，真正例）**：实际为正类，预测也为正类（预测正确）。  
- **FP（False Positive，假正例）**：实际为负类，预测为正类（误报，预测错误）。  
- **TN（True Negative，真负例）**：实际为负类，预测也为负类（预测正确）。  
- **FN（False Negative，假负例）**：实际为正类，预测为负类（漏报，预测错误）。

简单记法：
- 第一个字母（T/F）表示预测是否正确；
- 第二个字母（P/N）表示预测结果是正类还是负类。
  -> Score = 0.5973 (len=0.991, kw=1.000, sim=0.000)

Candidate 3: 在混淆矩阵中：

- **TP（True Positive，真正例）**：实际为正类，预测也为正类（正确预测阳性）。
- **FP（False Positive，假正例）**：实际为负类，但预测为正类（错误地预测为阳性）。
- **TN（True Negative，真负例）**：实际为负类，预测也为负类（正确预测阴性）。
- **FN（False Negative，假负例）**：实际为正类，但预测为负类（错误地预测为阴性）。

这些值用于评估分类模型的性能，如准确率、精确率、召回率等。
  -> Score = 0.5941 (len=0.980, kw=1.000, sim=0.000)

Selected: Candidate 2

================================================================================
Prompt 8: What is regularization and what problem does it address?
参考答案: Regularization adds a penalty term to the loss function to constrain model complexity and reduce overfitting.
--------------------------------------------------------------------------------
Candidate 1: 正则化（Regularization）是一种通过在模型训练过程中添加惩罚项来限制模型复杂度的技术，目的是防止过拟合（overfitting）。它通过抑制参数过大或减少特征的影响力，提高模型的泛化能力。常见的正则化方法包括L1正则化（Lasso）和L2正则化（Ridge）。
  -> Score = 0.1498 (len=0.249, kw=0.250, sim=0.000)

Candidate 2: 正则化（Regularization）是一种通过在损失函数中添加惩罚项来限制模型复杂度的技术，用于解决**过拟合**问题。

当模型过于复杂（如参数过多）时，容易在训练数据上表现很好，但在新数据上泛化能力差。正则化通过抑制参数过大（如L1、L2正则化），使模型更简单，从而提升泛化性能。
  -> Score = 0.1023 (len=0.341, kw=0.000, sim=0.000)

Candidate 3: 正则化（Regularization）是一种通过在模型训练过程中添加惩罚项来限制模型复杂度的技术，目的是防止过拟合（overfitting）。它通过抑制参数过大或减少特征的影响力，使模型更具泛化能力。常见的正则化方法有L1正则化（Lasso）和L2正则化（Ridge）。
  -> Score = 0.1498 (len=0.249, kw=0.250, sim=0.000)

Selected: Candidate 1

================================================================================
Prompt 9: Describe the main steps of k-means clustering.
参考答案: k-means repeatedly assigns samples to the nearest cluster center and then updates the cluster centers until convergence.
--------------------------------------------------------------------------------
Candidate 1: k-means聚类的主要步骤如下：

1. **选择簇数 k**：确定要划分的簇的数量 k。

2. **初始化中心点**：随机选择 k 个数据点作为初始聚类中心（质心）。

3. **分配数据点**：计算每个数据点到各个质心的距离（通常用欧氏距离），将其分配给最近的质心所属的簇。

4. **更新质心**：重新计算每个簇的质心，即该簇中所有点的均值。

5. **迭代重复**：重复步骤3和4，直到质心不再显著变化，或达到最大迭代次数。

6. **收敛**：算法收敛，输出最终的簇划分结果。

目标是最小化簇内平方和（WCSS, Within-Cluster Sum of Squares）。
  -> Score = 0.3691 (len=0.980, kw=0.250, sim=0.000)

Candidate 2: k-means聚类的主要步骤如下：

1. **选择簇数k**：确定要划分的簇的数量k。

2. **初始化中心点**：随机选择k个数据点作为初始聚类中心（质心）。

3. **分配数据点**：计算每个数据点到各个质心的距离（通常用欧氏距离），将其分配给最近的质心所属的簇。

4. **更新质心**：重新计算每个簇的质心，即该簇中所有数据点的均值。

5. **迭代**：重复步骤3和4，直到质心不再显著变化，或达到最大迭代次数。

6. **收敛**：算法收敛后，输出最终的聚类结果。

核心思想：最小化簇内平方和（WCSS），使同一簇内的点尽可能接近，不同簇的点尽可能远离。
  -> Score = 0.3723 (len=0.991, kw=0.250, sim=0.000)

Candidate 3: k-means聚类的主要步骤如下：

1. **确定簇数k**：事先指定要划分的簇的数量k。

2. **初始化中心点**：随机选择k个数据点作为初始的聚类中心（质心）。

3. **分配数据点**：计算每个数据点到各个质心的距离（常用欧氏距离），将其分配给最近的质心所属的簇。

4. **更新质心**：重新计算每个簇的质心，即该簇中所有数据点的均值。

5. **迭代优化**：重复步骤3和4，直到质心不再显著变化，或达到最大迭代次数。

6. **收敛输出**：算法收敛后，输出最终的k个簇及其对应的质心。

目标是最小化簇内平方和（WCSS, Within-Cluster Sum of Squares）。
  -> Score = 0.3743 (len=0.998, kw=0.250, sim=0.000)

Selected: Candidate 3

================================================================================
Prompt 10: Explain the meaning of the ROC curve and AUC.
参考答案: The ROC curve shows the trade-off between true positive rate and false positive rate at different thresholds, and AUC is the area under this curve that summarizes the model’s overall discriminative ability.
--------------------------------------------------------------------------------
Candidate 1: ROC曲线（受试者工作特征曲线）是评估二分类模型性能的工具，横轴是假正率（FPR），纵轴是真正率（TPR）。它反映在不同分类阈值下，模型对正类的识别能力。

AUC（曲线下面积）是ROC曲线下的面积，取值在0到1之间。AUC越大，模型分类性能越好。一般认为：

- AUC ≈ 1：模型效果极好  
- AUC = 0.5：模型无区分能力（相当于随机猜测）  
- AUC < 0.5：模型表现比随机还差（可能存在问题）

简言之，AUC衡量的是模型将正样本排在负样本前面的概率。
  -> Score = 0.4577 (len=0.998, kw=0.500, sim=0.021)

Candidate 2: ROC曲线（受试者工作特征曲线）是用于评估二分类模型性能的工具，横轴是假正率（FPR），纵轴是真正率（TPR）。通过绘制不同分类阈值下的TPR和FPR点，形成曲线。

AUC（曲线下面积）是ROC曲线下的面积，取值在0到1之间。AUC越大，模型分类性能越好：
- AUC ≈ 1：模型效果很好；
- AUC = 0.5：模型无区分能力（相当于随机猜测）；
- AUC < 0.5：模型表现比随机还差（可能需要检查数据或模型）。

简言之，ROC + AUC 能综合反映模型在不同阈值下的分类能力，且对类别不平衡不敏感。
  -> Score = 0.4637 (len=0.991, kw=0.500, sim=0.041)

Candidate 3: ROC曲线（受试者工作特征曲线）是评估二分类模型性能的工具，横轴是假正率（FPR），纵轴是真正率（TPR）。它反映在不同阈值下模型对正负样本的区分能力。

AUC（曲线下面积）是ROC曲线下的面积，取值在0到1之间。AUC越大，模型分类性能越好：
- AUC ≈ 1：模型效果很好；
- AUC = 0.5：模型无区分能力（相当于随机猜测）；
- AUC < 0.5：模型表现比随机还差（可能存在问题）。

简言之，AUC衡量的是模型将正样本排在负样本前面的概率。
  -> Score = 0.4528 (len=0.980, kw=0.500, sim=0.022)

Selected: Candidate 2
```

